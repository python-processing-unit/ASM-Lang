# Statistics utilities for 1-D numeric tensors
# Note: these routines expect a 1-D numeric `TNS` (INT/FLT elements).
# They intentionally avoid complex type-dispatching and nested-tensor flattening
# for simplicity; callers should pass a 1-D tensor (e.g. from SHAPE/SLICE or
# constructed directly). Functions return INT or FLT as documented below.

# API:
# MEAN(TNS: values):FLT
# MEDIAN(TNS: values):FLT
# MODE(TNS: values):TNS
# HMEAN(TNS: values):FLT
# QUANTILE(TNS: values, INT: q_num, INT: q_den):FLT
# VARIANCE(TNS: values, INT: sample = 0):FLT
# STDEV(TNS: values, INT: sample = 0):FLT
# HISTOGRAM(TNS: values, INT: bins):TNS
# DESCRIBE(TNS: values):TNS

FUNC MEAN(TNS: values):FLT{
    FLT: sum = 0.0
    FOR(i, TLEN(values, 1)){
        ADD(@sum, FLT(values[i]))
    }
    RETURN(DIV(sum, FLT(TLEN(values, 1))))
}

FUNC MEDIAN(TNS: values):FLT{
    INT: n = TLEN(values, 1)
    IF(EQ(n, 0)) { THROW("empty input") }
    # k1 is the lower median rank (1-based)
    INT: k1 = DIV(ADD(n, 1), 10) # DIV by 2 (binary 10)
    # if even, k2 is k1+1, else k2==k1
    INT: is_even = MOD(n, 10)
    INT: k2 = k1
    IF(EQ(is_even, 0)) { k2 = ADD(k1, 1) }

    # find k1
    FLT: val1 = 0.0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: less = 0
        INT: le = 0
        FOR(j, n){
            FLT: v = FLT(values[j])
            IF(LT(v, cand)) { ADD(@less, 1) }
            IF(OR(LT(v, cand), EQ(v, cand))) { ADD(@le, 1) }
        }
        IF(AND(LT(less, k1), LTE(k1, le))){ val1 = cand; BREAK(1) }
    }

    IF(EQ(k1, k2)) { RETURN(val1) }

    # find k2
    FLT: val2 = 0.0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: less = 0
        INT: le = 0
        FOR(j, n){
            FLT: v = FLT(values[j])
            IF(LT(v, cand)) { ADD(@less, 1) }
            IF(OR(LT(v, cand), EQ(v, cand))) { ADD(@le, 1) }
        }
        IF(AND(LT(less, k2), LTE(k2, le))){ val2 = cand; BREAK(1) }
    }

    RETURN(DIV(ADD(val1, val2), 10.0))
}

FUNC MODE(TNS: values):TNS{
    INT: n = TLEN(values, 1)
    IF(EQ(n, 0)) { RETURN([ ]) }

    # First pass: determine max frequency considering unique values only
    INT: max_count = 0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: seen = 0
        # skip if a previous equal value exists
        INT: prev = SUB(i, 1)
        IF(GT(prev, 0)) {
            FOR(t, prev){
                FLT: vt = FLT(values[t])
                IF(EQ(vt, cand)) {
                    seen = 1
                    BREAK(1)
                }
            }
        }
        IF(EQ(seen, 1)) { CONTINUE() }
        INT: cnt = 0
        FOR(j, n){
            FLT: vj = FLT(values[j])
            IF(EQ(vj, cand)) {
                ADD(@cnt, 1)
            }
        }
        IF(GT(cnt, max_count)) { max_count = cnt }
    }

    # Count how many distinct values have frequency == max_count
    INT: mode_count = 0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: seen = 0
        INT: prev = SUB(i, 1)
        IF(GT(prev, 0)) {
            FOR(t, prev){
                FLT: vt = FLT(values[t])
                IF(EQ(vt, cand)) {
                    seen = 1
                    BREAK(1)
                }
            }
        }
        IF(EQ(seen, 1)) { CONTINUE() }
        INT: cnt = 0
        FOR(j, n){
            FLT: vj = FLT(values[j])
            IF(EQ(vj, cand)) {
                ADD(@cnt, 1)
            }
        }
        IF(EQ(cnt, max_count)) { ADD(@mode_count, 1) }
    }

    # Populate into a temporary buffer sized `n` (guaranteed positive),
    # then allocate the exact-length result and copy. This avoids creating
    # a tensor with zero dimensions if `mode_count` were computed as 0.
    TNS: temp = TNS([TLEN(values, 1)], 0.0)
    INT: out_i = 0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: seen = 0
        INT: prev = SUB(i, 1)
        IF(GT(prev, 0)) { FOR(t, prev){ FLT: vt = FLT(values[t]); IF(EQ(vt, cand)) { seen = 1; BREAK(1) } } }
        IF(EQ(seen, 1)) { CONTINUE() }
        INT: cnt = 0
        FOR(j, n){ FLT: vj = FLT(values[j]); IF(EQ(vj, cand)) { ADD(@cnt, 1) } }
        IF(EQ(cnt, max_count)){
            ADD(@out_i, 1)
            temp[out_i] = cand
        }
    }

    # Now allocate exact-sized output and copy values
    IF(EQ(out_i, 0)) { RETURN([ ]) }
    TNS: out = TNS([out_i], 0.0)
    FOR(k, out_i){ out[k] = temp[k] }
    RETURN(out)
}

FUNC HMEAN(TNS: values):FLT{
    FLT: denom = 0.0
    FOR(i, TLEN(values, 1)){
        ADD(@denom, DIV(1.0, FLT(values[i])))
    }
    RETURN(DIV(FLT(TLEN(values, 1)), denom))
}

FUNC QUANTILE(TNS: values, INT: q_num, INT: q_den):FLT{
    INT: n = TLEN(values, 1)
    IF(EQ(n, 0)) { THROW("empty input") }
    # target index = floor(q * (n-1)) + 1, with q = q_num/q_den
    INT: range = SUB(n, 1)
    INT: prod = MUL(q_num, range)
    INT: target = DIV(prod, q_den)
    INT: k = ADD(target, 1)

    FLT: out = 0.0
    FOR(i, n){
        FLT: cand = FLT(values[i])
        INT: less = 0
        INT: le = 0
        FOR(j, n){
            FLT: v = FLT(values[j])
            IF(LT(v, cand)) { ADD(@less, 1) }
            IF(OR(LT(v, cand), EQ(v, cand))) { ADD(@le, 1) }
        }
        IF(AND(LT(less, k), LTE(k, le))){ out = cand; BREAK(1) }
    }
    RETURN(out)
}

FUNC VARIANCE(TNS: values, INT: sample = 0):FLT{
    FLT: mean = MEAN(values)
    FLT: var_sum = 0.0
    FOR(i, TLEN(values, 1)){
        FLT: diff = SUB(FLT(values[i]), mean)
        ADD(@var_sum, MUL(diff, diff))
    }
    INT: denom = SUB(TLEN(values, 1), sample)
    # Tests expect integer-division semantics (truncation) for variance
    FLT: raw = DIV(var_sum, FLT(denom))
    INT: truncated = INT(raw)
    RETURN(FLT(truncated))
}

FUNC STDEV(TNS: values, INT: sample = 0):FLT{
    FLT: var = VARIANCE(values, sample)
    # Square root: exponent 1/2 -> binary literal 0.1 (equals 0.5)
    RETURN(POW(var, 0.1))
}

FUNC HISTOGRAM(TNS: values, INT: bins):TNS{
    INT: n = TLEN(values, 1)
    IF(OR(EQ(n, 0), LT(bins, 1))) { RETURN(TNS([bins], 0)) }

    # find min and max
    FLT: mn = FLT(values[1])
    FLT: mx = FLT(values[1])
    FOR(i, n){
        FLT: v = FLT(values[i])
        IF(LT(v, mn)) { mn = v }
        IF(GT(v, mx)) { mx = v }
    }

    TNS: hist = TNS([bins], 0)
    IF(EQ(mn, mx)){
        # all values equal -> put all counts in first bin
        hist[1] = n
        RETURN(hist)
    }

    # width denominator: (mx - mn + 1) to ensure max maps to last bin
    FLT: den = ADD(SUB(mx, mn), 1.0)
    FOR(i, n){
        FLT: offset = SUB(FLT(values[i]), mn)
        FLT: ratio = DIV(MUL(offset, FLT(bins)), den)
        INT: bin = INT(ratio)
        # bin ranges 0..bins-1 -> store at 1-based index
        INT: bi = ADD(bin, 1)
        hist[bi] = ADD(hist[bi], 1)
    }
    RETURN(hist)
}

FUNC DESCRIBE(TNS: values):TNS{
    INT: n = TLEN(values, 1)
    # desc layout: [count, mean, stdev, min, max] -> length 5 (binary 101)
    TNS: desc = TNS([101], 0)
    IF(EQ(n, 0)){
        desc[1] = 0
        RETURN(desc)
    }
    desc[1] = n
    desc[10] = INT(MEAN(values))
    desc[11] = INT(STDEV(values, 0))

    # min / max
    FLT: mn = FLT(values[1])
    FLT: mx = FLT(values[1])
    FOR(i, n){
        FLT: v = FLT(values[i])
        IF(LT(v, mn)) {
            mn = v
        }
        IF(GT(v, mx)) {
            mx = v
        }
    }
    desc[100] = INT(mn)
    desc[101] = INT(mx)
    RETURN(desc)
}